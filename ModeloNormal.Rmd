---
title: "Distribución Gaussiana (alias 'La Normal')"
author: "Rodrigo Zepeda"
output:
  html_document:
    css: css/bootstrap.css
    includes:
      after_body: headers/footer.html
      before_body: headers/head.html
      in_header: headers/format.html
    number_sections: yes
    self_contained: no
    toc: yes
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
linkcolor: blue
urlcolor: blue
bibliography: referencias.bib
---

```{r setup, include=FALSE}
require(knitr)
require(kableExtra)
require(gridExtra)
require(ggplot2)
require(reshape2)
require(data.tree)

#Knitr table options
options(knitr.table.format = "html") 

#Chunk options
opts_chunk$set(echo = FALSE)
opts_chunk$set(results = 'asis')
opts_chunk$set(fig.width  = 4)
opts_chunk$set(fig.height = 4)
opts_chunk$set(fig.align='center')

#Function for authomatic theorem, corollary, example, counterexample, property, lemma and definition numbering
source("Rfun/theorem_creator.R")
```


```{r echo=FALSE, out.width='50%'}
knitr::include_graphics('images/paranormal.jpg')
```

# Deducción del Modelo

Pensemos que estamos midiendo la posición de las estrellas en el cielo. Para ello hay dos formas. 

```{r, fig.width=6}
ggplot() + 
  geom_line(aes(x = c(0,5), y = c(0,0)), linetype = "dashed") +
  geom_line(aes(x = c(0,0), y = c(0,-2)), linetype = "dashed") +
  geom_point(aes(x = 0, y = 0, color = "Mi estimación"), size = 3) + 
  geom_point(aes(x = 5, y = -2, color = "Estrella"), size = 5) +
  theme_bw() +
  scale_color_manual("Valores", values = c("Mi estimación" = "red", "Estrella" = "orange")) +
  annotate("text", x = 2.5, y = 0.1, label = "Error x") + 
  annotate("text", x = -0.2, y = -1, label = "Error y", angle = 90) +
  ggtitle("Mediciones de la posición de una estrella \nen coordenadas cartesianas") +
  xlab("Coordenada x") +
  ylab("Coordenada y")
```

Bajo coordenadas cartesianas $(x,y)$ pensemos que el error de medición es independiente; es decir, si $\rho(x,y)$ es la densidad conjunta de los errores en cada coordenada entonces:

$$
\rho (x,y) = f_X(x) f_Y(y) 
$$

Podemos asumir que los errores de medición tienen la misma distribución en la coordenada $x$ que la coordenada $y$:

$$
\rho (x,y) = f_X(x) f_X(y) 
$$

Por otro lado, supongamos que existe también una representación en coordenadas polares de la posición de la estrella: 
$$
p (r, \theta)  = g_R(r) 
$$

donde el error de medición depende sólo del radio $R$ (no del ángulo). 

```{r, fig.width=6}
ggplot() + 
  geom_line(aes(x = c(0,5), y = c(0,-2)), linetype = "dashed") +
  geom_point(aes(x = 0, y = 0, color = "Mi estimación"), size = 3) + 
  geom_point(aes(x = 5, y = -2, color = "Estrella"), size = 5) +
  theme_bw() +
  scale_color_manual("Valores", values = c("Mi estimación" = "red", "Estrella" = "orange")) +
  annotate("text", x = 2, y = -1, label = "Error r", angle = atan2(-2,5)*180/pi) +
  ggtitle("Mediciones de la posición de una estrella \nen coordenadas polares") +
  xlab("Coordenada x") +
  ylab("Coordenada y")
```



Notamos entonces que:

$$
f_X(x) f_X(y) = g_R\Big( \sqrt{x^2 + y^2} \Big) 
$$
donde sustituimos $r$ por su definición en coordenadas polares. Si tomamos $y = 0$ tenemos que $f_X(x) f_X(0) = g_R(x)$ (a partir de aquí supondré $x > 0$; los otros casos son similares). A partir de esa expresión se tiene que:

$$
f_X(\sqrt{x^2 + y^2} ) f_X(0) = g_R(\sqrt{x^2 + y^2} )
$$

Podemos entonces sustituir:

$$
f_X(x) f_X(y) = f_X(\sqrt{x^2 + y^2} ) f_X(0)
$$

y dividimos entre $f_X(0)^2$ para normalizar: 

$$
\dfrac{f_X(x) \cdot f_X(y)}{f_X(0)\cdot f_X(0)} = \dfrac{f_X\Big( \sqrt{x^2 + y^2} \Big) }{f_X(0)}
$$

Tomamos logaritmo:
$$
\ln \Big(\dfrac{f_X(x)}{f_X(0)}\Big) + \ln \Big(\dfrac{f_X(y)}{f_X(0)}\Big)  = \ln \Bigg( \dfrac{f_X\Big( \sqrt{x^2 + y^2} \Big) }{f_X(0)} \Bigg)
$$

Si reescribimos $h(x) = \ln \Big(\dfrac{f_X(x)}{f_X(0)}\Big)$ tenemos entonces que el problema es hallar una función $h$ tal que:

$$
h(x) + h(y) = h\Big(\sqrt{x^2+y^2}\Big)
$$

Pensando que dicha función es diferenciable podríamos buscarla haciendo:

$$
\dfrac{\partial}{\partial x} \Big[ h(x) + h(y) \Big] = \dfrac{\partial}{\partial x} h\Big(\sqrt{x^2+y^2}\Big)
$$

De donde obtenemos:

$$
h'(x) = h'(\sqrt{x^2 + y^2}) \dfrac{x}{\sqrt{x^2+y^2}}
$$

Notamos entonces que:

$$
\dfrac{h'(x)} {h'(\sqrt{x^2 + y^2})}= \dfrac{x}{\sqrt{x^2+y^2}}
$$ 

Por lo cual, una propuesta para $h'(x) = \alpha x$ para alguna $\alpha$ (no es la única solución al problema, de hecho hay infinitas) y se sigue que $h(x) =  \alpha x^2/2 + C$. La constante debe ser cero pues se tiene que: 

$$
\underbrace{h(x) + h(y)}_{ \alpha x^2/2 +  \alpha y^2/2 + 2C} = \underbrace{h\Big(\sqrt{x^2+y^2}\Big)}_{ \alpha(x^2+y^2)/2 + C}
$$

Al sustituir se tiene que:

$$
\ln \Big( \dfrac{f_X(x)}{f_X(0)} \Big)= \dfrac{\alpha x^2}{2}
$$

de donde despejamos y obtenemos:

$$
f_X(x) = \frac{1}{f_X(0)} e^{\frac{\alpha x^2
}{2}}
$$

Finalmente sabemos que para ser densidad debe integrar a $1$ y ser positiva (por tanto $f_X(0) > 0$) por tanto esto fuerza a $\alpha$ a ser negativo. En particular tomaremos $\alpha = -1$ por ser el negativo más sencillo para este problema (pudo haber sido cualquier otro negativo). 

$$
f_X(x) = \frac{1}{f_X(0)} e^{-\frac{1}{2} x^2}
$$

Y para que integre a $1$:
$$
1 = \int\limits_{-\infty}^{\infty} f_X(x) dx = \frac{1}{f_X(0)} \int\limits_{-\infty}^{\infty}  e^{-\frac{1}{2} x^2} dx
$$

Por tanto $f_X(0) = \int\limits_{-\infty}^{\infty}  e^{-\frac{1}{2} x^2} dx$. La siguiente sección se dedica a evaluar dicha integral. 

# Integración de la gaussiana

De la sección anterior notamos que sólo nos falta por integrar: 

$$
\int\limits_{-\infty}^{\infty}  e^{-\frac{1}{2} x^2} dx
$$

la cual puede reescribirse como:

$$
2 \int\limits_{0}^{\infty}  e^{-\frac{1}{2} x^2} dx
$$

Por lo que la integral a resolver en este caso es $\int\limits_{0}^{\infty}  e^{-\frac{1}{2} x^2} dx$. Para ello definiremos una función auxiliar $g$ que nos ayudará en el proceso de integración: 

$$
g(t) = \Big[ \int\limits_{0}^{t}  e^{-\frac{1}{2} x^2} dx \Big]^2
$$

Notamos que:

$$
\lim_{t \to \infty} \sqrt{g(t)} = \int\limits_{0}^{\infty}  e^{-\frac{1}{2} x^2} dx
$$

De donde toda nuestra atención se enfocará en ese límite. Para resolverlo utilizaremos [el truco de Feynman](http://fy.chalmers.se/~tfkhj/FeynmanIntegration.pdf) una técnica que no se estudia en las clases tradicionales de Cálculo^[Otra opción es usar integrales polares pero no necesariamente todos sabemos hacerlo.]. 

La derivada de $g$ está dada por:

$$
\dfrac{dg}{dt} = 2 \Bigg[ \int\limits_{0}^{t} e^{-x^2/2}dx \Bigg] e^{-t^2/2} = 2 \int\limits_{0}^{t} e^{-(t^2+x^2)/2}dx
$$

Hacemos el cambio de variable $u = x/t$ lo que implica que $x = ut$ y que $dx = tdu$ donde además cuando $x \in (0,t)$ entonces $u \in (0,1)$:


$$
\dfrac{dg}{dt} =  2 \int\limits_{0}^{1} t e^{-(1+u^2)t^2 /2}du
$$

Notamos que:

$$
\dfrac{\partial}{\partial t}  \Bigg[ - \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg] = 2te^{-(1+u^2)t^2/2}
$$

En resumen:

$$
\dfrac{dg}{dt} = \int\limits_{0}^{1} \dfrac{\partial}{\partial t}  \Bigg[ - \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg]  du = \dfrac{d}{d t}  \int\limits_{0}^{1}  \Bigg[ - \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg]  du 
$$

Por tanto, mediante integración obtenemos que:

$$
g(t) =  \int\limits_{0}^{1}  \Bigg[ - \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg]  du  + C
$$

Para determinar la constante de integración $C$ observamos que si $t \to 0$ se tiene:

$$
\lim_{t\to 0} g(t) = \Big[ \int\limits_{0}^{0}  e^{-\frac{1}{2} x^2} dx \Big]^2 = 0
$$

Mientras que por otro lado:

\begin{equation}
\begin{aligned}
\lim_{t\to 0}  g(t) &=  \lim_{t\to 0}   \int\limits_{0}^{1}  \Bigg[ - \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg]  du  + C 
\\ & = \lim_{t\to 0}   -2 \int\limits_{0}^{1}  \Bigg[  \dfrac{1}{1+u^2} \Bigg]  du  + C 
\\ & = -2\arctan(u)\Bigg|_{u = 0}^{u = 1} + C 
\\ & = -2 \dfrac{\pi}{4} + C 
\end{aligned}
\end{equation}

Por tanto, $C = \pi/2$. Finalmente, $g(t) = \int\limits_{0}^{1}  \Bigg[ - \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg]  du  + \dfrac{\pi}{2}$. Por otro lado, notamos que:

$$
\lim_{t \to \infty} g(t) = \int\limits_{0}^{1}  \Bigg[ - \lim_{t \to \infty} \dfrac{2e^{-(1+u^2)t^2/2}}{1+u^2} \Bigg]  du  + \dfrac{\pi}{2} = \dfrac{\pi}{2}
$$

Por lo cual:
$$
\lim_{t \to \infty} \sqrt{g(t)} = \int\limits_{0}^{\infty}  e^{-\frac{1}{2} x^2} dx  = \sqrt{\dfrac{\pi}{2}}
$$

De donde:

$$
\int\limits_{-\infty}^{\infty}  e^{-\frac{1}{2} x^2} dx = \sqrt{2 \pi}
$$
Concluimos entonces que $f_X(0) = \sqrt{2 \pi}$ lo cual nos permite definir la distribución normal estándar:

```{r}
form <- "
Una variable aleatoria $Z$ tiene una distribución $\\text{NormalEstándar}$ (o $\\text{Normal}(0,1)$) si:
$$
f_X(x) =  \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{x^2}{2}} 
$$

"

build_theorem("Modelo",form, proof = "", name = "Normal Estándar", id ="normal" )
```

A partir de un cambio de variable podemos definir el modelo $\text{Normal}(\mu,\sigma^2)$ en general:

```{r}
form <- "
Sea $Z$ variable aleatoria $Z$ con distribución $\\text{NormalEstándar}$ (o $\\text{Normal}(0,1)$). Para $\\sigma > 0$ definimos una nueva variable aleatoria $X$ dada por:
$$
X = \\sigma Z + \\mu
$$
Entonces la función de densidad de $X$ es:
$$
f_X(x) = \\dfrac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} 
$$
"

dem <- "
Operaremos con la función de distribución acumulada:
\\begin{equation}
\\begin{aligned}
F_X(x) & = \\mathbb{P}(X \\leq x) \\\\
& = \\mathbb{P}(\\sigma Z + \\mu \\leq x) \\\\
& = \\mathbb{P}( Z  \\leq \\frac{x - \\mu}{\\sigma}) \\\\
& = F_Z\\Big( \\frac{x - \\mu}{\\sigma} \\Big)
\\end{aligned}
\\end{equation}
de donde, al derivar, obtenemos la densidad:
\\begin{equation}
\\begin{aligned}
f_X(x) & = \\dfrac{d}{dx} F_X(x) \\\\
& = \\dfrac{d}{dx} F_Z\\Big( \\frac{x - \\mu}{\\sigma}  \\Big) \\\\
& = f_Z\\Big( \\frac{x - \\mu}{\\sigma} \\Big) \\cdot \\frac{1}{\\sigma} \\\\
& =  \\dfrac{1}{\\sqrt{2\\pi}} e^{-\\frac{\\big(\\frac{x - \\mu}{\\sigma}\\big)^2}{2}}\\cdot \\frac{1}{\\sigma}\\\\
& = \\dfrac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} 
\\end{aligned}
\\end{equation}
"

build_theorem("Teorema",form, proof = dem, name = "Normal($\\mu,\\sigma$)", id ="normalgral" )
```

```{r}
form <- "
Una variable aleatoria $X$ se distribuye $\\text{Normal}(\\mu,\\sigma)$ si su densidad está dada por:
$$
f_X(x) = \\dfrac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} 
$$
"

build_theorem("Modelo",form, proof = "", name = "Normal($\\mu,\\sigma$)", id ="normalgral2" )
```

La normal se ve así:

```{r, fig.width=8}
xvec <- seq(-5,10,length.out = 1000)
ggplot() +
  geom_line(aes(x = xvec, y = dnorm(xvec,0,1), color = "µ = 0 & σ = 1")) +
  geom_line(aes(x = xvec, y = dnorm(xvec,0,2), color = "µ = 0 & σ = 2")) +
  geom_line(aes(x = xvec, y = dnorm(xvec,0,0.5), color = "µ = 0 & σ = 0.5")) +
  geom_line(aes(x = xvec, y = dnorm(xvec,5,1), color = "µ = 5 & σ = 1")) +
  geom_line(aes(x = xvec, y = dnorm(xvec,5,0.5), color = "µ = 5 & σ = 0.5")) +
  geom_line(aes(x = xvec, y = dnorm(xvec,5,2), color = "µ = 5 & σ = 2")) +
  theme_bw() +
  ggtitle("Diferentes densidades normales") +
  scale_color_manual("Parámetros", values = rainbow(6)) +
  xlab("x") +
  ylab("y")
  
```



<!--
# Funciones generadoras, valor esperado y otras características

# Teorema central del límite
-->